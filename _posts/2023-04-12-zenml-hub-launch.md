---
layout: post
author: "Hamza Tahir"
title: "Introducing ZenML Hub: Streamlining MLOps Collaboration with Reusable Components"
description: "ZenML is launching the ZenML Hub, a novel plugin system that allows users to contribute and consume stack component flavors, pipelines, steps, materializers, and other pieces of code seamlessly in their ML pipelines."
category: zenml
tags: tooling zenml evergreen llm foundationmodels hub
publish_date: April 12, 2023
date: 2023-04-12T00:02:00Z
thumbnail: /assets/posts/hub/hub-launch-cover-small.png
image:
  path: /assets/posts/hub/hub-launch-cover.png
---

**Last updated:** April 12, 2023

![*Image generated by [Midjourney v5](https://www.midjourney.com/)*](/assets/posts/hub/hub-launch-cover.png)

Today, we are excited to announce the launch of the ZenML Hub, a major game-changer for our open-source MLOps framework. This [novel plugin system](https://docs.zenml.io/starter-guide/collaborate/zenml-hub) allows users to contribute and consume [stack component flavors](https://docs.zenml.io/component-gallery/categories), [pipelines](https://docs.zenml.io/starter-guide/pipelines), [steps](https://docs.zenml.io/starter-guide/pipelines/parameters-and-caching), [materializers](https://docs.zenml.io/advanced-guide/pipelines/materializers), and other pieces of code seamlessly in their ML pipelines.

The goal of ZenML is to [standardize MLOps workflows](https://blog.zenml.io/zenml-mlops-framework/) across a rich and diverse ML tooling ecosystem. To achieve this, we have built key abstractions of components that allow users to integrate together a variety of tooling and infrastructure backends, without having to change their business layer logic. This allows MLOps practitioners to standardize processes, prevent vendor lock-in, and ensure reliability across their workflows:


<figure>
  <img src="/assets/posts/hub/hub.png" alt="ZenML: Standardizing and integrating MLOps components agnostic of tooling and infrastructure" style="width:100%;max-width:300px;">
  <figcaption style="text-align:center;font-size:14px;color:#666;">ZenML: Standardizing and integrating MLOps components agnostic of tooling and infrastructure</figcaption>
</figure>

Some examples of using these components in practice are:

- Starting locally and transitioning to a production-ready [orchestrator](https://docs.zenml.io/component-gallery/orchestrators) like [Kubeflow](https://www.kubeflow.org/) or [Airflow](https://airflow.apache.org/) with no code changes
- Versioning and tracking data locally and in an [S3](https://docs.zenml.io/component-gallery/artifact-stores/s3) bucket by just changing the [artifact store](https://docs.zenml.io/component-gallery/artifact-stores)
- [Tracking experiments](https://docs.zenml.io/component-gallery/experiment-trackers) and models in [MLflow](https://docs.zenml.io/component-gallery/experiment-trackers/mlflow), [Weights & Biases](https://docs.zenml.io/component-gallery/experiment-trackers/wandb), and [Neptune](https://docs.zenml.io/component-gallery/experiment-trackers/neptune) seamlessly within a pipeline
- Running steps in [dedicated environments](https://docs.zenml.io/component-gallery/step-operators) for preprocessing and training like [Sagemaker](https://docs.zenml.io/component-gallery/step-operators/sagemaker) or [Spark](https://docs.zenml.io/component-gallery/step-operators/spark-kubernetes) jobs
- Deploying models with production-grade deployment tools like [BentoML](https://docs.zenml.io/component-gallery/model-deployers/bentoml), [Seldon](https://docs.zenml.io/component-gallery/model-deployers/seldon), etc.

## üîå Leveraging standard plugins

Before today, these ZenML components were packaged within the core ZenML package and exposed via the `zenml integration` command line. While useful, this made it harder to modify and contribute more of these components for users and our community. With the launch of the ZenML Hub, we're making big strides toward making these components more widely accessible and easier to use than ever. In the Hub, ZenML stack component flavors, steps, materializers, and other pieces of useful code are packaged in `plugins`. These `plugins` are accessible [via a central registry that is available directly from the ZenML dashboard](https://docs.zenml.io/starter-guide/collaborate/zenml-hub).  Each plugin contains descriptions, tags, and helpful information on how to use it.

<figure>
  <img src="/assets/posts/hub/hub_search_plugins.gif" alt="ZenML plugins are searchable from within the dashboard" style="width:100%;max-width:300px;">
  <figcaption style="text-align:center;font-size:14px;color:#666;">ZenML plugins are searchable from within the dashboard</figcaption>
</figure>


To use a plugin, one simply needs to install it as follows:

```bash
zenml hub install langchain_qa_example
```

‚Ä¶ and then directly import and use it in Python, for example:

```bash
from zenml.hub.langchain_qa_example import qa_pipeline
```

<aside>
üí° Currently, the ZenML Hub supports steps and pipelines, with support for all other ZenML abstractions coming soon (flavors, materializers, etc).
</aside>

## üå™Ô∏è Creating reproducible, standardized, and testable code for your team

<figure>
  <img src="/assets/posts/hub/hub_submit_plugin.gif" alt="Easily create a plugin through the ZenML dashboard" style="width:100%;max-width:300px;">
  <figcaption style="text-align:center;font-size:14px;color:#666;">Easily create a plugin through the ZenML dashboard</figcaption>
</figure>


With the hub, extending ZenML has never been easier. Contributing a plugin is a breeze: simply create and submit a public Github repository (like [this](https://github.com/zenml-io/zenml-hub-plugin-template)). After processing, your plugin is installable for all ZenML users, including your company and the community at large. This will foster a community-driven approach to building machine learning workflows. As more users contribute to the Hub, the community will benefit from a growing repository of high-quality, reusable components that can be used to build more complex workflows. This in turn enables users to create more impactful and efficient models while also providing the opportunity to collaborate with other community members.

We believe that the ZenML Hub will help democratize MLOps by making it easier for everyone to contribute and consume code. By removing the barriers to entry for new contributors, we hope to accelerate innovation in the field and ultimately lead to more impactful solutions. The ultimate goal is to come to a series of standardized, reusable, components that will help all of us who are putting models in production.

## Use Cases

The ZenML Hub is inspired by similar projects such as the [HuggingFace Hub](https://huggingface.co/docs/hub/index),  [Kubeflow Components,](https://github.com/kubeflow/pipelines/tree/master/components) [LlamaIndex Hub,](https://llamahub.ai/) [Langchain Hub, and](https://github.com/hwchase17/langchain-hub) [TFX Add-ons](https://github.com/tensorflow/tfx-addons/tree/main/tfx_addons). The ZenML Hub shares synergies with a lot of these services, and delivers similar value. One of the key use cases for the ZenML Hub is sharing reproducible code across different projects within an organization. If an organization has multiple machine learning projects happening simultaneously, it can create a set of commonly-used steps that can be shared across all projects. These steps can include data loading, preprocessing, feature engineering, model training, and evaluation. By using the ZenML Hub, these components can be easily shared and reused across projects, saving time and effort.

Imagine a process where one user in your organization creates a standard wrapper to run a preprocessing job on Spark, a training job on Sagemaker, and a deployment job on AzureML. With the ZenML Hub, these components are discoverable, fully documented, and tested. The work is only done once, and the plugins can be updated, versioned, and maintained separately from the actual machine learning code.

## ü§ñ Example: QA Bot with LangChain, LLamaIndex and OpenAI

As part of this launch, we are excited to introduce several new plugins that have already been added to the ZenML Hub. These plugins include standard steps and pipelines that can be easily and freely used for standard use cases with ZenML. We look forward to seeing how these new plugins will streamline the ML workflow and help everyone build better models faster.

<figure>
  <img src="/assets/posts/hub/hub_plugin_details.png" alt="Plugins allow you to reuse code across projects" style="width:100%;max-width:300px;">
  <figcaption style="text-align:center;font-size:14px;color:#666;">Plugins allow you to reuse code across projects</figcaption>
</figure>

Perhaps one of the most intuitive examples to get started with is the `langchain_qa_example` plugin. The plugin features a simple pipeline and steps that allow users to fetch data from a variety of sources (via [Langchain](https://github.com/hwchase17/langchain) and [LlamaIndex](https://github.com/jerryjliu/llama_index) data loading steps), create an index, and answer a query across the corpus using a GPT-3.5 (and beyond) LLM powered by OpenAI. To reproduce it locally, simply do:

```bash
zenml hub install langchain_qa_example
export OPENAI_KEY=<YOUR_KEY> # get it from https://platform.openai.com/account/api-keys
```

```bash
from zenml.hub.langchain_qa_example import build_zenml_docs_qa_pipeline

pipeline = build_zenml_docs_qa_pipeline(question="What is ZenML?", load_all_paths=False).run()
```

(When you first run this pipeline, it will run a series of steps that will scrape the [ZenML docs](https://docs.zenml.io), and build an index. Subsequent runs will be faster and re-use the index because of ZenML‚Äôs internal cache.)

And there you go: You can now recreate a simple question-answering MLOps pipeline using cutting-edge LLMs and the latest libraries, which you can now go on to deploy on custom infrastructure. Of course, if you did want to use the individual steps or pipelines directly, feel free to check out the corresponding project and source code [here]( https://github.com/zenml-io/zenml-projects/tree/main/langchain-qa-hub).

## üì° What next?

In the future, we plan to add more plugins, with steps like an ONNX converter and step operators like Sagemaker, Spark, EMR, etc. We're also working on workflows to easily pull and fork public plugins, automated testing, and a playground to test steps.

For now ([release 0.38.0 onwards](https://github.com/zenml-io/zenml/releases)),
the ZenML Hub is officially supported within the main ZenML package. Get started
with using your [first
plugin](https://docs.zenml.io/starter-guide/collaborate/zenml-hub) and [start
contributing](https://github.com/zenml-io/zenml-hub-plugin-template) today. Your
contributions will help build a better future for machine learning and benefit
the entire community. Thank you for your continued support, and stay tuned for
more exciting updates from the ZenML team!
