---
layout: post
author: "Alex Strick van Linschoten"
title: "Unleashing More Power and Flexibility with ZenML's New Pipeline and Step Syntax"
description: "The 0.40.0 release introduces a completely reworked interface for developing
your ZenML steps and pipelines. It makes working with these components much more natural, intuitive, and enjoyable."
category: zenml
tags: zenml evergreen framework
publish_date: May 26, 2023
date: 2023-05-26T00:02:00Z
thumbnail: /assets/posts/pipeline-syntax/new_pipelines-small.png
image:
  path: /assets/posts/pipeline-syntax/new_pipelines.png
---

**Last updated:** May 26, 2023

![*Image generated by [Midjourney v5](https://www.midjourney.com/)*](/assets/posts/pipeline-syntax/new_pipelines.png)

The 0.40.0 release introduces a completely reworked interface for developing
your ZenML steps and pipelines.

In our continuous efforts to simplify and enhance your experience with ZenML,
we're thrilled to roll out a significant update that relates to our pipeline and
step definition syntax. This substantial modification, the culmination of user
feedback and internal testing, is designed to make working with ZenML
much more natural, intuitive, and enjoyable.

At the core of this change we wanted to make it more flexible to work with two of ZenML's core building blocks: pipelines and steps. We've overhauled the syntax with the primary aim to get out of your way and allow you to focus on what really matters: building efficient, reproducible, and robust machine learning pipelines.

We believe these improvements will make a considerable difference in your ZenML experience. Let's dive into the new features that you will love using!

## No More BaseParameters Class

In the previous version, you had to define a separate class for step parameters using `BaseParameters`. This is no longer necessary, although it is still supported for backward compatibility. You can now pass parameters directly in the step function:

```python
@step 
def trainer(data: pd.Dataframe, lr: float = 0.1, gamma: Optional[float] = 0.02) -> ...:
    print(lr)
    print(gamma)
```

## Simplified Pipeline Execution

With the new changes, you no longer need to create a pipeline instance and then run it separately. You can now pass parameters directly at pipeline instance creation and execute the pipeline in a single step:

```python
my_pipeline(lr=0.000001)
```

You can now call steps multiple times inside a pipeline, allowing you to create more complex workflows and reuse steps with different parameters:

```python
@pipeline
def my_pipeline(step_count: int) -> None:
    data = load_data_step()
    after = []
    for i in range(step_count):
        train_step(data, learning_rate=i * 0.0001, name=f"train_step_{i}")
        after.append(f"train_step_{i}")
    model = select_model_step(..., after=after)
```

Pipelines can now define inputs and outputs, providing a clearer interface for working with data and dependencies between pipelines:

```python
@pipeline(enable_cache=False)
def subpipeline(pipeline_param: int):
    out = step_1(k=None)
    step_2(a=3, b=pipeline_param)
    return 17
```

You can now call pipelines within other pipelines. This currently does not execute the inner pipeline but instead adds its steps to the parent pipeline, allowing you to create modular and reusable workflows:

```python
@pipeline(enable_cache=False)
def my_pipeline(a: int = 1):
    p1_output = subpipeline(pipeline_param=22)
    step_2(a=a, b=p1_output)
```

## Increased flexibility when defining steps

Steps can now have `Optional`, `Union`, and `Any` type annotations for their inputs and outputs. Additionally, default values are allowed for step inputs.

```python
@step
def trainer(data: pd.Dataframe, start_model: Union[svm.SVC, svm.SVR], coef0: Optional[int] = None) -> Any:
    pass
```

You can now easily run a step outside of a pipeline, making it easier to test and debug your code:

```python
trainer(data=pd.Dataframe(...), start_model=svc.SVC(...))
```

External artifacts can be used to pass values to steps that are not produced by an upstream step. This provides more flexibility when working with external data or models:

```python
from zenml.steps.external_artifact import ExternalArtifact

@pipeline
def my_pipeline(lr: float):
    data = process_data()
    trainer(data=data, start_model=ExternalArtifact(svc.SVC(...)))
```

## Get Started with the new interface and features!

To get started, simply import the new `@step` and `@pipeline` decorator and check out our new [starter guide](https://docs.zenml.io/user-guide/starter-guide) for more information.

```python
from zenml import step, pipeline

@step
def my_step(...):
    ...

@pipeline
def my_pipeline(...):
    ...
```

Note that the old pipeline and step interface is still working using the imports from previous ZenML releases but is deprecated and will be removed in the future.

If you run into any issues or want to discuss a specific use case, please reach out to us on [Slack](https://zenml.io/slack-invite/).
